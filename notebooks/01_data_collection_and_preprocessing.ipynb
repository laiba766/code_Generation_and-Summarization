{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Data Collection and Preprocessing\n",
    "## Code Summarization and Generation Project\n",
    "\n",
    "**Author:** Laiba Akram  \n",
    "**Student ID:** 42943  \n",
    "**Course:** Theory of Programming Languages  \n",
    "\n",
    "This notebook collects code snippets from various sources and extracts features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      2\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m../src\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'yaml'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_collector import DataCollector\n",
    "from feature_extractor import FeatureExtractor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded successfully\")\n",
    "print(f\"Languages: {config['data']['languages']}\")\n",
    "print(f\"Target functions per language: {config['data']['sampling']['target_functions_per_lang']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collect Code Snippets\n",
    "\n",
    "Collect function-level code snippets from your source repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = DataCollector(config)\n",
    "\n",
    "# Example: Collect from a directory\n",
    "# Replace with your actual code repository path\n",
    "# collected_functions = collector.collect_from_directory('/path/to/repositories')\n",
    "# collector.save_dataset(collected_functions, '../data/raw')\n",
    "\n",
    "print(\"Data collection complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Features\n",
    "\n",
    "Extract AST-based features, complexity metrics, and PL-level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FeatureExtractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m extractor = \u001b[43mFeatureExtractor\u001b[49m()\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Example: Process one language at a time\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# for language in ['python', 'java', 'javascript', 'rust']:\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#     input_file = f'../data/raw/{language}_functions.jsonl'\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#     output_file = f'../data/processed/{language}_features.csv'\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#     df = extractor.process_dataset(input_file, output_file)\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFeature extraction complete\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'FeatureExtractor' is not defined"
     ]
    }
   ],
   "source": [
    "extractor = FeatureExtractor()\n",
    "\n",
    "# Example: Process one language at a time\n",
    "# for language in ['python', 'java', 'javascript', 'rust']:\n",
    "#     input_file = f'../data/raw/{language}_functions.jsonl'\n",
    "#     output_file = f'../data/processed/{language}_features.csv'\n",
    "#     df = extractor.process_dataset(input_file, output_file)\n",
    "\n",
    "print(\"Feature extraction complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all language datasets\n",
    "# dfs = []\n",
    "# for language in ['python', 'java', 'javascript', 'rust']:\n",
    "#     df = pd.read_csv(f'../data/processed/{language}_features.csv')\n",
    "#     dfs.append(df)\n",
    "\n",
    "# combined_df = pd.concat(dfs, ignore_index=True)\n",
    "# combined_df.to_csv('../data/processed/all_features.csv', index=False)\n",
    "\n",
    "# print(f\"Combined dataset shape: {combined_df.shape}\")\n",
    "# print(f\"Languages: {combined_df['language'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load combined dataset\n",
    "# df = pd.read_csv('../data/processed/all_features.csv')\n",
    "\n",
    "# Display basic statistics\n",
    "# print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "# print(\"\\nMissing values:\")\n",
    "# print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of complexity metrics by language\n",
    "# metrics = ['ast_depth', 'cc_mccabe', 'halstead_volume']\n",
    "\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# for idx, metric in enumerate(metrics):\n",
    "#     df.boxplot(column=metric, by='language', ax=axes[idx])\n",
    "#     axes[idx].set_title(f'{metric} by Language')\n",
    "#     axes[idx].set_xlabel('Language')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('../results/visualizations/metric_distributions.png', dpi=300)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
